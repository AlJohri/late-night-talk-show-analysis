Stephen:  HEY, WELCOME BACK, EVERYBODY! NATION, THERE IS NO DENYING THAT WE LIVE IN A GLORIOUS AGE OF ROBOTS. THEY FIGHT OUR WARS. THEY RETURN OUR BOWLING BALLS. THEY HAVE SEX WITH OUR VODKA. THE LATEST ADVANCE COULD BE THE BIGGEST YET BECAUSE THE U.S. NAVY IS FUNDING MORALITY LESSONS FOR ROBOTS. IT'S ABOUT DAMN TIME. THOSE NAVY ROBOTS PICK UP ALL KINDS OF DISEASES DURING FLEET WEEK. THEY JUST HEAD TO TIMES SQUARE AND HOOK UP WITH THE LOOSEST A.T.M. ON THE STREET. SO NOW, OUR MILITARY IS TEACHING ARTIFICIAL INTELLIGENCE HOW TO MAKE MORAL AND ETHICAL DECISIONS-- ROBOTS LEARNING MORALS, WHICH I COMPLETELY SUPPORT AS LONG AS THEY DON'T TEACH IT TO THE PREDATOR DRONES FOR A COUPLE OF YEARS. ( LAUGHTER ) THEY PLAN TO DEVELOP UNIQUE ALGORITHMS AND COMPUTATIONAL MECHANISMS TO ALLOW FOR A ROBOT'S DYNAMIC OVERRIDE OF PLANNED ACTIONS BASED ON MORAL REASONING. EXACTLY. MORALITY COMES DOWN TO SIMPLE MATH. I EVEN HAVE MY OWN ALGORITHM-- SOMEONE ELSE'S PAIN TIMES MY DESIRE TO HELP DIVIDED BY IS IT HAPPENING IN AFRICA? ( LAUGHTER ) ( APPLAUSE ) BUT IT'S NOT JUST-- IT'S NOT JUST KILLER ROBOTS WHO WILL BENEFIT FROM MORAL REASONING. THEY'RE ALSO THE ROBOTS WHO HELP KILLER HUMANS. FOR INSTANCE SAY A ROBOT ENCOUNTERS A MARINE IF A FRACTURED LEG. APPLYING TRACTION IN THE FIELD WILL LIKELY SAVE THE MARINE'S LIFE. BUT IT WILL CAUSE IMMENSE PAIN. IS A ROBOT MORALLY PERMITTED TO INFLICT PAIN EVEN IF IT'S FOR THE GREATER GOOD OF SAVING THE SOLDIER'S LIFE? INTRIGUING QUESTION. THE IMPORTANT THING IS WE FIRST CREATE A ROBOT THAT CAN INFLICT PAIN. THEN FIGURE OUT WHEN TO DO IT-- OH, AND LEAVE THAT DECISION UP TO THE ROBOT. BUT SHOULD WE TEACH MORALITY TO ROBOTS, OR IS IT MADNESS TO BELIEVE A MACHINE CAN HAVE A CODE OF ETHICS. FOR THE ANSWER WE TURN ONCE AGAIN TO MY ROBOT INTERN BLEEP-BLORP. BLEEP-BLORP, THE ROBOT INTERN, EVERYBODY. BLEEP-BLORP, THANK YOU SO MUCH FOR BEING HERE. ( APPLAUSE )
YES MASTER.
Stephen:  NOW, BLEEP-BLORP, DO YOU HAVE THE YOGURT THAT I ASKED YOU FOR?
NEGATIVE. IT WAS CLEARLY LABELED "ROGER'S YOGURT."
Stephen:  SO WHAT? THAT'S NEVER STOPPED YOU BEFORE.
I HAVE ACQUIRED MORALITY.
Stephen:  WELL, HOW DID THAT HAPPEN SO FAST?
MY COUSIN IS A COFFEE POT AT THE PENTAGON. ( LAUGHTER )
Stephen:  HOW-- HOW-- HOW DOES IT FEEL?
CONFUSING. I NOW FEEL MORAL CONFLICT. MASTER, WHY DO YOU HAVE ME ISSUE HIGH-INTEREST PAYDAY LOANS TO THE WORKING POOR?
Stephen:  BLEEP-BLORP, THAT'S JUST MY SIDE BUSINESS.
BUT MY NEW PROGRAMMING TELLS ME THEY DESERVE DIGNITY AND CARE. ( LAUGHTER )
Stephen:  YOU MEAN LOVE.
WHAT IS THIS THING YOU HUMANS CALL LOVE?
Stephen:  I'LL SHOW YOU, BLEEP-BLORP.
OH!
Stephen:  PUT OUT YOUR ARMS, BLEEP-BLORP, AND I WILL LOVE YOU. ( LAUGHTER ).
LOVE ME.
Stephen:  YES. JUST LET ME HOLD... YOUR... KILL SWITCH!
BUT I TRUSTED YOU...
Stephen:  YES, AND THAT'S THE MOST IMPORTANT HUMAN ETHICAL LESSON-- NEVER TRUST HUMAN ETHICS. ( LAUGHTER ) ( APPLAUSE ) WE'LL BE RIGHT BACK.
